1.title:"A new way of automating statistical testing methods"
1.abstract:"We propose a novel way of automating statistical structural testing of software, based on the combination of uniform generation of combinatorial structures, and of randomized constraint solving techniques. More precisely, we show how to draw test cases which balance the coverage of program structures according to structural testing criteria. The control flow graph is formalized as a combinatorial structure specification. This provides a way of uniformly drawing execution paths which have suitable properties. Once a path has been drawn, the predicate characterizing those inputs which lead to its execution is solved using a constraint solving library. The constraint solver is enriched with powerful heuristics in order to deal with resolution failures and random choice strategies."
1.url:http://dx.doi.org/10.1109/ASE.2001.989785
1.opinion:exclude

2.title:"Automatic test data generation for programs with integer and float variables"
2.abstract:"The paper presents a novel approach for automated test data generation of imperative programs containing integer, boolean and/or float variables. Our approach is based on consistency techniques integrating integer and float variables. We handle statement, branch and path coverage criteria. Our purpose is thus to automatically generate test data that will cause the program to execute a statement, to traverse a branch or to traverse a specified path. For path coverage, the specified path is transformed into a path constraint which is solved by an interval-based constraint solving algorithm handling integer, boolean and real variables. A valid test input is then extracted from the interval solutions. For statement (and branch) coverage, a path reaching the specified statement or branch is dynamically constructed. Our algorithm for path coverage is then applied. The search for a suitable path and the solving of path constraints make extensive use of consistency techniques. We propose a simple consistency notion called eBox consistency, for generalizing box consistency to integer and float variables. The eBox consistency is sufficient for our purpose. A prototype has been developed and experimental results show the feasibility of our approach. This work is an extension of work by A. Gotlieb (2000) for float and boolean variables."
2.url:http://dx.doi.org/10.1109/ASE.2001.989786
2.opinion:exclude

3.title:"TestEra: a novel framework for automated testing of Java programs"
3.abstract:"We present TestEra, a novel framework for automated testing of Java programs. TestEra automatically generates all non-isomorphic test cases within a given input size and evaluates correctness criteria. As an enabling technology, TestEra uses Alloy, a first-order relational language, and the Alloy Analyzer. Checking a program with TestEra involves modeling the correctness criteria for the program in Alloy and specifying abstraction and concretization translations between instances of Alloy models and Java data structures. TestEra produces concrete Java inputs as counterexamples to violated correctness criteria. The paper discusses TestEra's analyses of several case studies: methods that manipulate singly linked lists and red-black trees, a naming architecture, and a part of the Alloy Analyzer."
3.url:http://dx.doi.org/10.1109/ASE.2001.989787
3.opinion:exclude

4.title:"Generating EDI message translations from visual specifications"
4.abstract:"Electronic data interchange (EDI) systems are used in many domains to support inter-organisational information exchange. To get systems using different EDI message formats to communicate, complex message translations (where data must be transformed from one EDI message format into another), are required. We describe a visual language and support environment which greatly simplify the task of the systems integrator by using a domain-specific visual language to express data formats and format translations. Complex message translations are automated by an underlying transformation engine. We describe the motivation for this system, its key visual language and transformation engine features, a prototype environment, and experience translating it into a commercial product."
4.url:http://dx.doi.org/10.1109/ASE.2001.989788
4.opinion:exclude

5.title:"The synthesis of a Java card tokenisation algorithm"
5.abstract:"We describe the development of a Java bytecode optimisation algorithm by the methodology of program extraction. We develop the algorithm as a collection of proofs and definitions in the Coq proof assistant, and then use Coq's extraction mechanism to automatically generate a program in OCaml. The extraction methodology guarantees that this program is correct. We discuss the feasibility of the methodology and suggest some improvements that could be made."
5.url:http://dx.doi.org/10.1109/ASE.2001.989789
5.opinion:exclude

6.title:"Wins and losses of algebraic transformations of software architectures"
6.abstract:"In order to understand, analyze and modify software, we commonly examine and manipulate its architecture. For example, we may want to examine the architecture at different levels of abstraction. We can view such manipulations as architectural transformations, and more specifically, as graph transformations. We evaluate relational algebra as a way of specifying and automating the architectural transformations. Specifically, we examine Grok, a relational calculator that is part of the PBS toolkit. We show that relational algebra is practical in that we are able to specify many of the transformations commonly occurring during software maintenance and, using a tool like Grok, we are able to manipulate, quite efficiently, large software graphs; this is a \"win\". However, this approach is not well suited to express some types of transforms involving patterns of edges and nodes; this is a \"loss\". By means of a set of examples, the paper makes clear when the approach wins and when it loses."
6.url:http://dx.doi.org/10.1109/ASE.2001.989790
6.opinion:exclude

7.title:"Acceptance based assurance"
7.abstract:"Assurance of software systems has traditionally been sought through the rigour of the development process. The higher the assurance, the more demanding the development process; the highest assurance requiring the use of formal methods during development. This approach has been followed for decades with some success, but increased assurance brings a disproportionate increase in cost and risk. A change in emphasis is suggested from the development of a system to its acceptance. The benefits for high assurance systems are illustrated through a case study and preliminary experience of high assurance techniques are reported."
7.url:http://dx.doi.org/10.1109/ASE.2001.989791
7.opinion:exclude

8.title:"Specification modeling and validation applied to a family of network security products"
8.abstract:"A high-bandwidth, always-on Internet connection makes computers in homes and small offices attractive targets for network-based attacks. Network security gateways can protect such vulnerable hosts from attackers, but differing sets of customer needs require different feature mixes. The safest way to address this market is to provide a family of products, each member of which requires little or no end-user configuration. Since the products are closely related, the effort to validate n of them should be much less than n times the effort to validate one; however validating the correctness and security of even one such device is notoriously difficult, due to the oft-observed fact that no practical amount of testing can show the absence of security flaws. One would instead like to prove security properties, even when the products are implemented using off-the-shelf technologies that don't lend themselves to formal reasoning. The author describes how the specification modeling and validation tools of the Interactive Specification Acquisition Tools (ISAT) suite are used to help validate members of a particular family of network security gateway products built using widely available open source technologies."
8.url:http://dx.doi.org/10.1109/ASE.2001.989792
8.opinion:exclude

9.title:"Certifying domain-specific policies"
9.abstract:"Proof-checking code for compliance to safety policies potentially enables a product-oriented approach to certain aspects of software certification. To date, previous research has focused on generic, low-level programming-language properties such as memory type safety. In this paper we consider proof-checking higher-level domain-specific properties for compliance to safety policies. The paper first describes a framework related to abstract interpretation in which compliance to a class of certification policies can be efficiently calculated. Membership equational logic is shown to provide a rich logic for carrying out such calculations, including partiality, for certification. The architecture for a domain-specific certifier is described, followed by an implemented case study. The case study considers consistency of abstract variable attributes in code that performs geometric calculations in Aerospace systems."
9.url:http://dx.doi.org/10.1109/ASE.2001.989793
9.opinion:exclude

10.title:"Automated validation of software models"
10.abstract:"The paper describes the application of an automated verification tool to a software model developed at Ford Motor Company. Ford already has in place an advanced model-based software development framework that employs the Matlab(R), Simulink(R), and Stateflow(R) modeling tools. During this project, we applied the invariant checker Salsa to a Simulink(R)/Stateflow(R) model of automotive software to check for nondeterminism, missing cases, dead code, and redundant code. During the analysis, a number of anomalies were detected that had not been found during manual review. We argue that the detection and correction of these problems demonstrates a cost-effective application of formal verification that elevates our level of confidence in the model."
10.url:http://dx.doi.org/10.1109/ASE.2001.989794
10.opinion:exclude

11.title:"Context-aware browsing of large component repositories"
11.abstract:"The paper proposes a novel approach to locating software components from a large component repository: context-aware browsing. Without any explicit input from software developers, this approach automatically locates and presents a list of software components that could possibly be used in the current development situation. This automation of the component location process not only greatly reduces the search space of components so that software developers can easily browse and choose the desired components, but also enables software developers to use components whose existence they do not even anticipate. A software agent that supports context-aware browsing has been developed and evaluated."
11.url:http://dx.doi.org/10.1109/ASE.2001.989795
11.opinion:exclude

12.title:"Identification of high-level concept clones in source code"
12.abstract:"Source code duplication occurs frequently within large software systems. Pieces of source code, functions, and data types are often duplicated in part or in whole, for a variety of reasons. Programmers may simply be reusing a piece of code via copy and paste or they may be \"re-inventing the wheel\". Previous research on the detection of clones is mainly focused on identifying pieces of code with similar (or nearly similar) structure. Our approach is to examine the source code text (comments and identifiers) and identify implementations of similar high-level concepts (e.g., abstract data types). The approach uses an information retrieval technique (i.e., latent semantic indexing) to statically analyze the software system and determine semantic similarities between source code documents (i.e., functions, files, or code segments). These similarity measures are used to drive the clone detection process. The intention of our approach is to enhance and augment existing clone detection methods that are based on structural analysis. This synergistic use of methods will improve the quality of clone detection. A set of experiments is presented that demonstrate the usage of semantic similarity measure to identify clones within a version of NCSA Mosaic."
12.url:http://dx.doi.org/10.1109/ASE.2001.989796
12.opinion:exclude

13.title:"Static consistency checking for distributed specifications"
13.abstract:"Software engineers building a complex system make use of a number of informal and semi-formal notations. We describe a framework, xlinkit, for managing the consistency of development artifacts expressed in such notations. xlinkit supports distributed software engineering by providing a distribution-transparent language for expressing constraints between specifications. It specifies a semantics for those constraints that permits the generation of hyperlinks between inconsistent elements. We give a formal semantics for link generation, and show how we expressed the rules of the UML foundation/core modules in our language. We outline how we implemented xlinkit as a light-weight web service using open standard technology and present the results of an evaluation against several sizeable UML models provided by industrial partners."
13.url:http://dx.doi.org/10.1109/ASE.2001.989797
13.opinion:exclude

14.title:"Test purposes: adapting the notion of specification to testing"
14.abstract:"Nowadays, test cases may correspond to elaborate programs. It is therefore sensible to try to specify test cases in order to get a more abstract view of these. This paper explores the notion of test purpose as a way to specify a set of test cases. It shows how test purposes are exploited today by several tools that automate the generation of test cases. It presents the major relations that link test purposes, test cases and reference specification. It also explores the similarities and differences between the specification of test cases, and the specification of programs. This opens perspectives for the synthesis and the verification of test cases, and for other activities like test case retrieval."
14.url:http://dx.doi.org/10.1109/ASE.2001.989798
14.opinion:exclude

15.title:"Monitoring programs using rewriting"
15.abstract:"We present a rewriting algorithm for efficiently testing future time Linear Temporal Logic (LTL) formulae on finite execution traces. The standard models of LTL are infinite traces, reflecting the behavior of reactive and concurrent systems which conceptually may be continuously alive. In most past applications of LTL, theorem provers and model checkers have been used to formally prove that down-scaled models satisfy such LTL specifications. Our goal is instead to use LTL for up-scaled testing of real software applications, corresponding to analyzing the conformance of finite traces against LTL formulae. We first describe what it means for a finite trace to satisfy an LTL formula and then suggest an optimized algorithm based on transforming LTL formulae. We use the Maude rewriting logic, which turns out to be a good notation and being supported by an efficient rewriting engine for performing these experiments. The work constitutes part of the Java PathExplorer (JPAX) project, the purpose of which is to develop a flexible tool for monitoring Java program executions."
15.url:http://dx.doi.org/10.1109/ASE.2001.989799
15.opinion:exclude

16.title:"Program execution based module cohesion measurement"
16.abstract:"Module cohesion describes the degree to which different actions performed by a module contribute towards a unified function. High module cohesion is a desirable property of a program. The program modifications during successive maintenance interventions can have negative effect on the structure of the program resulting in less cohesive modules. Therefore, metrics that measure module cohesion are important for software restructuring during maintenance. The existing static slice based module cohesion metrics significantly overestimate cohesion due to the limitations of static slicing. In this paper, we present a novel program execution based approach to measure module cohesion of legacy software. We define cohesion metrics based on definition-use pairs in the dynamic slices of the outputs. Our approach significantly improves the accuracy of cohesion measurement. We implemented our technique and measured module cohesion for several programs. Cohesion measurements using our technique were found to be more insightful than static slice based measurements."
16.url:http://dx.doi.org/10.1109/ASE.2001.989800
16.opinion:exclude

17.title:"Composition and refinement of behavioral specifications"
17.abstract:"This paper presents a mechanizable framework for specifying, developing, and reasoning about complex systems. The framework combines features from algebraic specifications, abstract state machines, and refinement calculus, all couched in a categorical setting. In particular, we show how to extend algebraic specifications to evolving specifications (especs) in such a way that composition and refinement operations extend to capture the dynamics of evolving, adaptive, and self-adaptive software development, while remaining efficiently computable. The framework is partially implemented in the Epoxi system."
17.url:http://dx.doi.org/10.1109/ASE.2001.989801
17.opinion:exclude

18.title:"Instantiating and detecting design patterns: putting bits and pieces together"
18.abstract:"Design patterns ease the designing, understanding, and re-engineering of software. Achieving a well-designed piece of software requires a deep understanding and a good practice of design patterns. Understanding existing software relies on the ability to identify architectural forms resulting from the implementation of design patterns. Maintaining software involves spotting places that can be improved by using better design decisions, like those advocated by design patterns. Nevertheless, there is a lack of tools automatizing the use of design patterns to achieve well-designed pieces of software, to identify recurrent architectural forms, and to maintain software. We present a set of tools and techniques to help OO software practitioners design, understand, and re-engineer a piece of software using design-patterns. A first prototype tool, PATTERNS-BOX, provides assistance in designing the architecture of a new piece of software, while a second prototype tool, PTIDEJ, identifies design patterns used in an existing one. These tools, in combination, support maintenance by highlighting defects in an existing design, and by suggesting and applying corrections based on widely-accepted design pattern solutions."
18.url:http://dx.doi.org/10.1109/ASE.2001.989802
18.opinion:exclude

19.title:"Connectors synthesis for deadlock-free component based architectures"
19.abstract:"Nowadays component-based technologies offer straightforward ways of building applications from existing components. Although these technologies might differ in terms of the level of heterogeneity among components they support, e.g. CORBA or COM versus J2EE, they all suffer the problem of dynamic integration. That is, once components are successfully integrated in a uniform context how is it possible to check, control and assess that the dynamic behavior of the resulting application will not deadlock? The authors propose an architectural, connector-based approach to this problem. We compose a system in such a way that it is possible to check whether and why the system deadlocks. Depending on the kind of deadlock, we have a strategy that automatically operates on the connector part of the system architecture in order to obtain a suitably equivalent version of the system which is deadlock-free."
19.url:http://dx.doi.org/10.1109/ASE.2001.989803
19.opinion:exclude

20.title:"Modeling and verification of distributed real-time systems based on CafeOBJ"
20.abstract:"CafeOBJ is a wide spectrum formal specification language based on multiple logical foundations: mainly initial and hidden algebra. A wide range of systems can be specified in CafeOBJ thanks to its multiple logical foundations. However, distributed real-time systems happen to be excluded from targets of CafeOBJ. The authors propose a method of modeling and verifying such systems based on CafeOBJ, together with timed evolution of UNITY computational models."
20.url:http://dx.doi.org/10.1109/ASE.2001.989804
20.opinion:exclude

21.title:"Generation of distributed system test-beds from high-level software architecture descriptions"
21.abstract:"Most distributed system specifications have performance benchmark requirements. However, determining the likely performance of complex distributed system architectures during development is very challenging. We describe a system where software architects sketch an outline of their proposed system architecture at a high level of abstraction, including indicating client requests, server services, and choosing particular kinds of middleware and database technologies. A fully working implementation of this system is then automatically generated, allowing multiple clients and servers to be run. Performance tests are then automatically run for this generated code and results are displayed back in the original high-level architectural diagrams. Architects may change performance parameters and architecture characteristics, comparing multiple test run results to determine the most suitable abstractions to refine to detailed designs for actual system implementation. We demonstrate the utility of this approach and the accuracy of our generated performance test-beds for validating architectural choices during early system development."
21.url:http://dx.doi.org/10.1109/ASE.2001.989805
21.opinion:exclude

22.title:"Tailoring a COTS group support system for software requirements inspection"
22.abstract:"The inspection of early life-cycle artifacts such as requirement documents promises great benefits. However, research demonstrates that the inspection process is complex and expensive and that tool support would be highly desirable. Existing inspection tools focus largely on the inspection of source code. We have therefore devised groupware support for inspecting requirements. Based on our experience with adopting a group support system (GSS) for requirements negotiation, we decided to tailor this commercial GSS to support inspection of requirements. The paper discusses our concept of a Groupware-supported Requirements Inspection Process (GRIP) and shows that tailoring a COTS GSS works well to automate this process."
22.url:http://dx.doi.org/10.1109/ASE.2001.989806
22.opinion:exclude

23.title:"Automatically restructuring programs for the Web"
23.abstract:"The construction of interactive server-side Web applications differs substantially from the construction of traditional interactive programs. In contrast, existing Web programming paradigms force programmers to save and restore control state between user interactions. We present an automated transformation that converts traditional interactive programs into standard CGI programs. This enables reuse of existing software development methodologies. Furthermore, an adaptation of existing programming environments supports the development of Web programs."
23.url:http://dx.doi.org/10.1109/ASE.2001.989807
23.opinion:exclude

24.title:"Unfriendly COTS integration - instrumentation and interfaces for improved plugability"
24.abstract:"It is becoming increasingly desirable to incorporate commercial-off-the-shelf (COTS) tools as software components into larger software systems. Due to their large user base, COTS tools tend to be cheap, reasonably reliable, and functionally powerful. Reusing them as components has the benefit of significantly reducing development cost and effort. Despite these advantages, developers encounter major obstacles in integrating most COTS tools because these tools have been constructed as stand-alone applications and make assumptions about their environment that do not hold when used as part of larger software systems. Most significantly, while they frequently contain programmatic interfaces that allow other components to obtain services from them on a direct call basis, they almost always lack the notification and data synchronicity facilities required for active integration. The authors present an integration framework for adding these notification and data synchronization facilities to COTS tools so that they can be integrated as active software components into larger systems. We illustrate our integration framework through tool suites we constructed around Mathworks' Matlab/Stateflow and Rational's Rose (two widely-used, large COTS tools). Our experience to date is that it is indeed possible to transform standalone COTS tools into software components."
24.url:http://dx.doi.org/10.1109/ASE.2001.989808
24.opinion:exclude

25.title:"Adequate reverse engineering"
25.abstract:"Reverse engineering a program constructs a high-level representation suitable for various software development purposes such as documentation or reengineering. Unfortunately however, there are no established guidelines to assess the adequacy of such a representation. We propose two such criteria, completeness and accuracy, and show how they can be determined during the course of reversing the representation. A representation is successfully reversed when it is given as input to a suitable code generator, and a program equivalent to the original is produced. To explore this idea, we reverse engineer a small but complex numerical application, represent our understanding using algebraic specifications, and then use a code generator to produce code from the specification. We discuss the strengths and weaknesses of the approach as well as alternative approaches to reverse engineering adequacy."
25.url:http://dx.doi.org/10.1109/ASE.2001.989809
25.opinion:exclude

26.title:"Enhancing partial-order reduction via process clustering"
26.abstract:"Partial-order reduction is a well-known technique to cope with the state-space-explosion problem in the verification of concurrent systems. Using the hierarchical structure of concurrent systems, we present an enhancement of the partial-order-reduction scheme of G.J. Holzman and D. Peled (1995) and D. Peled (1994). A prototype of the new algorithm has been implemented on top of the verification tool SPIN. The first experimental results are encouraging."
26.url:http://dx.doi.org/10.1109/ASE.2001.989810
26.opinion:exclude

27.title:"Exploiting heap symmetries in explicit-state model checking of software"
27.abstract:"Detecting symmetries in the structure of systems is a well known technique falling in the class of bisimulation (strongly) preserving state space reductions. Previous work in applying symmetries to aid model checking focuses mainly on process topologies and user specified data types. We applied the symmetry framework to model checking object-based programs that manipulate dynamically created objects, and developed a linear-time heuristic for finding the canonical representative of a symmetry equivalence class. The strategy was implemented in the object-based model checker dSPIN and some experiments, yielding encouraging results, have been carried out."
27.url:http://dx.doi.org/10.1109/ASE.2001.989811
27.opinion:exclude

28.title:"Combining static analysis and model checking for software analysis"
28.abstract:"We present an iterative technique in which model checking and static analysis are combined to verify large software systems. The role of the static analysis is to compute partial order information which the model checker uses to reduce the state space. During exploration, the model checker also computes aliasing information that it gives to the static analyzer which can then refine its analysis. The result of this refined analysis is then fed back to the model checker which updates its partial order reduction. At each step of this iterative process, the static analysis computes optimistic information which results in an unsafe reduction of the state space. However, we show that the process converges to a fixed point at which time the partial order information is safe and the whole state space is explored."
28.url:http://dx.doi.org/10.1109/ASE.2001.989812
28.opinion:exclude

29.title:"Towards a precise definition of the OMG/MDA framework"
29.abstract:"We are currently witnessing an important paradigm shift in information system construction, namely the move from object and component technology to model technology. The object technology revolution has allowed the replacement of the over twenty-year-old step-wise procedural decomposition paradigm with the more fashionable object composition paradigm. Surprisingly, this evolution seems to have triggered another even more radical change, the current trend toward model transformation. A concrete example is the Object Management Group's rapid move from its previous Object Management Architecture vision to the latest Model-Driven Architecture. This paper proposes an interpretation of this evolution through abstract investigation. In order to stay as language-independent as possible, we have employed the neutral formalism of Sowa's conceptual graphs to describe the various situations characterizing this organization. This will allow us to identify potential problems in the proposed modeling framework and suggest some possible solutions."
29.url:http://dx.doi.org/10.1109/ASE.2001.989813
29.opinion:exclude

30.title:"Shared variables interaction diagrams"
30.abstract:"Scenario-based specifications offer an intuitive and visual way of describing design requirements of distributed software systems. For the communication paradigm based on messages, message sequence charts (MSC) offer a standardized and formal notation amenable to formal analysis. In this paper we define shared variables interaction diagrams (SVID) as the counterpart of MSCs when processes communicate via shared variables. After formally defining SVIDs, we develop an intuitive as well as formal definition of refinement for SVIDs. This notion provides a basis for systematically adding details to SVID requirements."
30.url:http://dx.doi.org/10.1109/ASE.2001.989814
30.opinion:exclude

31.title:"Modeling class operations in B: Application to UML behavioral diagrams"
31.abstract:"An appropriate approach for translating UML to B formal specifications allows one to use UML and B jointly in a unified, practical and rigorous software development. We formally analyze UML specifications via their corresponding B formal specifications. This point is significant because B support tools like AtelierB are available. We can also use UML specifications as a tool for building B specifications, so the development of B specifications become easier In this paper we address the problem of automatic derivation from UML behavioral diagrams into B specifications, which has been so far an open issue. A new approach for modeling class operations in B is presented Each class operation is mapped into a B operation. A class operation and its involved data are mapped into the same B abstract machine (BAM). The class operation calling-called dependency is used to arrange derived B operations into BAMs. For each calling-called pair of class operations, the B operation of the called operation participates in the implementation of the B operation of the calling operation."
31.url:http://dx.doi.org/10.1109/ASE.2001.989815
31.opinion:exclude

32.title:"Automated software engineering using concurrent class machines"
32.abstract:"Concurrent Class Machines are a novel state-machine model that directly captures a variety of object-oriented concepts, including classes and inheritance, objects and object creation, methods, method invocation and exceptions, multithreading and abstract collection types. The model can be understood as a precise definition of UML activity diagrams which, at the same time, offers an executable, object-oriented alternative to event-based statecharts. It can also be understood as a visual, combined control and data flow model for multithreaded object-oriented programs. We first introduce a visual notation and tool for Concurrent Class Machines and discuss their benefits in enhancing system design. We then equip this notation with a precise semantics that allows us to define refinement and modular refinement rules. Finally, we summarize our work on generation of optimized code, implementation and experiments, and compare with related work."
32.url:http://dx.doi.org/10.1109/ASE.2001.989816
32.opinion:exclude

33.title:"Higher order function synthesis through proof planning"
33.abstract:"The close association between higher order functions and algorithmic skeletons is a promising source of automatic parallelisation of programs. An approach to automatically synthesizing higher order functions from functional programs through proof planning is presented Our work has been conducted within the context of a parallelising compiler for SML, with the objective of exploiting parallelism latent in potential higher order function use in programs."
33.url:http://dx.doi.org/10.1109/ASE.2001.989817
33.opinion:exclude

34.title:"AGATE, access graph based tools for handling encapsulation"
34.abstract:"Encapsulation and modularity are supported by various static access control mechanisms that manage implementation hiding and define interfaces adapted to different client profiles. Programming languages use numerous and very different mechanisms, the cumulative application of which is sometimes confusing and hard to predict. Furthermore, understanding and reasoning about access control independently from the programming languages is quite difficult. Tools based on a language-independent model of access control are presented to address these issues. These tools support access control handling via visualisation of access, checking of design requirements on access and source code generation. We believe in the contribution of such tools for improving understanding and enhancing use of access control from design to implementation."
34.url:http://dx.doi.org/10.1109/ASE.2001.989818
34.opinion:exclude

35.title:"A UML validation toolset based on abstract state machines"
35.abstract:"The Unified Modeling Language has become widely accepted as a standard in software development. Several tools have been produced to support UML model validation. These tools translate a UML model into a validation language such as PROMELA. However they have some shortcomings: there is no proof of correctness (with respect to the UML semantics) for these tools; and there is no tool that supports validation for both the static and dynamic aspects of a UML model. In order to overcome these shortcomings, we present a toolset which is based on the semantic model using abstract state machines. Since the toolset is derived from the semantic model, the toolset is correct with respect to the semantic model. In addition, this toolset can be used to validate both the static and dynamic aspects of a model."
35.url:http://dx.doi.org/10.1109/ASE.2001.989819
35.opinion:exclude

36.title:"Semi-automated verification of Erlang code"
36.abstract:"Erlang is a functional programming language with support for concurrency and message passing communication that is used at Ericsson for developing telecommunication applications. We consider the challenge of verifying temporal properties of systems programmed in Erlang with dynamically evolving process structures. To accomplish this, a rich verification framework for goal-directed, proof system-based verification is used. The paper investigates the problem of semi-automating the verification task by identifying the proof parameters crucial for successful proof search."
36.url:http://dx.doi.org/10.1109/ASE.2001.989820
36.opinion:exclude

37.title:"Automatic verification of Java design patterns"
37.abstract:"Design patterns are widely used by object oriented designers and developers for building complex systems in object oriented programming languages such as Java. However, systems evolve over time, increasing the chance that the pattern in its original form will be broken. We attempt to show that many design patterns (implemented in Java) can be verified automatically. Patterns are defined in terms of variants, mini-patterns, and artifacts in a pattern description language called SPINE. These specifications are then processed by Hedgehog, an automated proof tool that attempts to prove that Java source code meets these specifications."
37.url:http://dx.doi.org/10.1109/ASE.2001.989821
37.opinion:exclude

38.title:"Tracing execution of software for design coverage"
38.abstract:"Test suites are designed to validate the operation of a system against requirements. One important aspect of a test suite design is to ensure that system operation logic is tested completely. This is a difficult task. Code coverage tools support test suite designers by providing the information about which parts of source code are covered during system execution. Unfortunately, code coverage tools produce only source code coverage information. For a test engineer it is often hard to understand what the noncovered parts of the source code do and how they relate to requirements. We propose a generic approach that provides design coverage of the executed software, simplifying the development of new test suites. We demonstrate our approach on common design abstractions such as statecharts and structure diagrams. We implement the design coverage using tracing and a trace analysis framework. Using design coverage, test suites could be created faster by focussing on untested design elements."
38.url:http://dx.doi.org/10.1109/ASE.2001.989822
38.opinion:exclude

39.title:"Model checking for an executable subset of UML"
39.abstract:"The paper presents an approach to model checking software system designs specified in xUML (http://www.kc.com/html/xuml.html), an executable subset of UML. This approach is enabled by the execution semantics of xUML and is based on automatic translation from xUML to S/R, the input language of the COSPAN model checker (R.H. Hardin et al., 1996). Model transformations are applied to reduce the state space of the resulting S/R model that is to be verified by COSPAN. An xUML level logic for specifying properties to be checked is defined. Automated support is provided for translating properties specified in the logic to S/R representations and mapping error traces generated by COSPAN to xUML representations."
39.url:http://dx.doi.org/10.1109/ASE.2001.989823
39.opinion:exclude

40.title:"A technique for mutation of Java objects"
40.abstract:"Mutation analysis inserts faults into a program to create test sets that distinguish the mutant from the original program. Inserted faults must represent plausible errors. Standard transformations can mutate scalar values such as integers, floats, and character data. Mutating objects is an open problem, because object semantics are defined by the programmer and can vary widely. We develop mutation operators and support tools that can mutate Java library items that are heavily used in commercial software. Our mutation engine can support reusable libraries of mutation components to inject faults into objects that instantiate items from these common Java libraries. Our technique should be effective for evaluating real-world software testing suites."
40.url:http://dx.doi.org/10.1109/ASE.2001.989824
40.opinion:exclude

41.title:"Providing early feedback in the development cycle through automated application of model checking to software architectures"
41.abstract:"The benefits of evaluating properties of software architectures stem from two important software architecture roles: (1) providing an opportunity to evaluate requirements and correct defects prior to implementation; and (2) serving as a blueprint for system developers. The paper focuses on a new software architecture evaluation tool called Architecture Analysis Dynamic Environment (Arcade) that uses model checking to provide software architecture safety and liveness evaluation during the requirements gathering and analysis phase. Model checking requires expertise not typically held by systems analysts and software developers. Thus, two barriers to applying model checking must be addressed: (1) translation of the software architecture specification to a form suitable for model checking, and (2) interpretation of the results of model checking. Arcade provides an automated approach to these barriers, allowing model checking of software architectures to be added to the list of techniques available to software analysts and developers focusing on requirements gathering and analysis."
41.url:http://dx.doi.org/10.1109/ASE.2001.989825
41.opinion:exclude

42.title:"Automated check of architectural models consistency using SPIN"
42.abstract:"In recent years the necessity for handling different aspects of the system separately has introduced the need to represent SA (software architectures) from different viewpoints. In particular, behavioral views are recognized to be one of the most attractive features in the SA description, and in practical contexts, state diagrams and scenarios are the most widely used tools to model this view. Although very expressive, this approach has two drawbacks: system specification incompleteness and view consistency. Our work can be put in this context with the aim of managing incompleteness and checking view conformance: we propose the use of state diagrams and scenario models for representing system dynamics at the architectural level; they can be incomplete and we want to prove that they describe, from different viewpoints, the same system behavior. To reach this goal, we use the SPIN model checker and we implement a tool to manage the translation of architectural models in Promela and LTL."
42.url:http://dx.doi.org/10.1109/ASE.2001.989826
42.opinion:exclude

43.title:"Automating the performance and reliability analysis of enterprise information systems"
43.abstract:"Good quality models for the analysis of complex enterprise information systems (EIS) are hard to build and require lots of experience and effort, which are not always available. A possible solution to deal with the previous issue is to build automated procedures for quality model generation. Such procedures will encapsulate previous existing knowledge on quality modeling and their use will reduce the cost of developing quality models. The authors concentrate on the performance and reliability of EIS and investigate the automatic generation of quality models from EIS architectural descriptions comprising additional information related to the aspects that affect the quality of the EIS."
43.url:http://dx.doi.org/10.1109/ASE.2001.989827
43.opinion:exclude

44.title:"An analysis-revision cycle to evolve requirements specifications"
44.abstract:"We argue that the evolution of requirements specifications can be supported by a cycle composed of two phases: analysis and revision. We investigate an instance of such a cycle, which combines two techniques of logical abduction and inductive learning to analyze and revise specifications respectively."
44.url:http://dx.doi.org/10.1109/ASE.2001.989828
44.opinion:exclude

45.title:"Knowledge base approach to consistency management of UML specifications"
45.abstract:"The use of the Unified Modelling Language (UML) during systems development has been growing in scale and complexity, often resulting in inconsistent specifications. We present a knowledge base goal-driven approach for consistency management of UML specifications represented as axioms which define goals. We propose an inference procedure as a flexible pattern-based abduction used to build and morph paths based on the specifications. The approach involves a two-step interaction process between the specifications: observation and comparison. Prototypes of the knowledge base engine and of a tool to map UML specifications in XMI format (eXtensible Metadata Interchange) to the knowledge base have been developed to demonstrate and evaluate the approach."
45.url:http://dx.doi.org/10.1109/ASE.2001.989829
45.opinion:exclude

46.title:"Strategies for automated specification-based testing of synchronous software"
46.abstract:"The paper presents new techniques for specification based-testing of synchronous software with the Lutess tool. Lutess provides a framework consisting of automatically building generators which interact with the software under test and feed it with test input sequences. In the past few years, it has been established that operational profiles as well as scenarios are powerful tools, allowing for a better fault detection ability. As opposed to this last technique which relies on the ability of the human tester to specify scenarios, we propose an approach based solely on software specification to automatically generate input sequences which may correspond to fault revealing scenarios."
46.url:http://dx.doi.org/10.1109/ASE.2001.989830
46.opinion:exclude

47.title:"Developing generative frameworks using XML"
47.abstract:"Generative programming methods provide some significant advantages for the repeated deployment of product line architectures. The paper considers XML as a tool for building and describing applications that use generative programming methods. It describes techniques for the creation of a generative framework, presents a case study and discusses the results of practical application of these methods in a real world, enterprise scale, product line architecture. The paper presents the advantages of using an XML descriptor that can be easily transformed to generate both static and dynamically configurable software components for direct deployment in an application framework. Two implementation approaches are considered: an indirect approach using XSL for the transformations; and a direct approach where the XML descriptor is parsed and dealt with programmatically. The relative advantages of these two approaches are discussed. The paper provides practical examples and presents lessons learned from the application of the techniques."
47.url:http://dx.doi.org/10.1109/ASE.2001.989831
47.opinion:exclude

48.title:"A tool for lazy verification of security protocols"
48.abstract:"We present the lazy strategy implemented in a compiler of cryptographic protocols, Casrul. The purpose of this compiler is to verify protocols and to translate them into rewrite rules that can be used by several kinds of automatic or semi-automatic tools for finding flaws, or proving properties. It is entirely automatic, and the efficiency of the generated rules is guaranteed because of the use of a lazy model of intruder behavior. This efficiency is illustrated on several examples."
48.url:http://dx.doi.org/10.1109/ASE.2001.989832
48.opinion:exclude

49.title:"Generation of functional test sequences from B formal specifications presentation and industrial case-study"
49.abstract:"The paper presents an original method to generate test sequences. From formal specifications of the system to be tested, an equivalent system of constraints is derived, and then the domain of each state variable of this system is partitioned into subdomains. Using this partition, limit states are computed with a specific solver that uses constraint logic programming with sets. This specific solver is then used to build test sequences by traversing the constrained reachability graph of the specifications. Finally, the formal specifications are used as an oracle by using them to determine the expected output for a given input. The results of an industrial case-study of the Smart Card GSM 11-11 standard are presented and discussed."
49.url:http://dx.doi.org/10.1109/ASE.2001.989833
49.opinion:exclude

50.title:"Action Language Verifier"
50.abstract:"Action Language is a specification language for reactive software systems. We present the Action Language Verifier which consists of: 1) a compiler that converts Action Language specifications to composite symbolic representations, and 2) an infinite-state symbolic model checker which verifies (or falsifies) CTL properties of Action Language specifications. Our symbolic manipulator (Composite Symbolic Library) combines a BDD manipulator (for boolean and enumerated types) and a Presburger arithmetic manipulator (for integers) to handle multiple variable types. Since we allow unbounded integer variables, model checking queries become undecidable. We present several heuristics used by the Action Language Verifier to achieve convergence."
50.url:http://dx.doi.org/10.1109/ASE.2001.989834
50.opinion:exclude

51.title:"Scalable consistency checking between diagrams - the VIEWINTEGRA approach"
51.abstract:"The Unified Modeling Language (UML) supports a wide range of diagrams for modeling software development concerns. UML diagrams are independent but connected; their meta-model describes them under a common roof. Despite the advances of UML, we found that the problem of ensuring consistency between UML diagrams has not been solved. We have developed an approach for automated consistency checking, called VIEWINTEGRA.. Our approach provides excellent support for active (preventive) and passive (detective) consistency checking. We make use of consistent transformation to translate diagrams into interpretations and we use consistency comparison to compare those interpretations to other diagrams. Our approach was applied to a number of applications where we found the separation of transformation and comparison to be highly beneficial in addressing consistency-checking scalability and usability issues. The paper introduces our UML-based transformation framework, discusses how it aids comparison, and demonstrates how it improves consistency checking."
51.url:http://dx.doi.org/10.1109/ASE.2001.989835
51.opinion:exclude

52.title:"Better reasoning about software engineering activities"
52.abstract:"Software management oracles often contain numerous subjective features. At each subjective point, a range of behaviors is possible. Stochastic simulation samples a subset of the possible behaviors. After many such stochastic simulations, the TAR2 treatment learner can find control actions that have (usually) the same impact despite the subjectivity of the oracle."
52.url:http://dx.doi.org/10.1109/ASE.2001.989836
52.opinion:exclude

53.title:"Amphion/NAV: deductive synthesis of state estimation software"
53.abstract:"Previous work on domain-specific deductive program synthesis described the Amphion/NAIF system for generating Fortran code from high-level graphical specifications describing problems in space system geometry. Amphion/NAIF specifications describe input-output functions that compute geometric quantities (e.g., the distance between two planets at a point in time, or the time when a radio communication path between a spacecraft and earth is occluded) by composing together Fortran subroutines from the NAIF subroutine library developed at the Jet Propulsion Laboratory. In essence, Amphion/NAIF synthesizes code for glueing together the NAIF components in a way such that the generated code implements the specification, with a concurrently generated proof that this implementation is correct. Amphion/NAIF demonstrated the success of domain-specific deductive program synthesis and is still in use today within the space science community. However, a number of questions remained open that we will attempt to answer in this paper."
53.url:http://dx.doi.org/10.1109/ASE.2001.989837
53.opinion:exclude

54.title:"Programs are abstract data types"
54.abstract:"We propose to view programs as abstract data types and to perform program changes by applying well-defined operations on programs. The ADT view of programs goes beyond the approach of syntax-directed editors and proof-editors since it is possible to combine basic update operations into larger update programs that can be stored and reused. It is crucial for the design of update operations and their composition to know which properties they can preserve when they are applied to a program. The author argues in favor of the abstract data type view of programs, and presents a general framework in which different programming languages, update languages, and properties can be studied."
54.url:http://dx.doi.org/10.1109/ASE.2001.989838
54.opinion:exclude

55.title:"An automated tool for analyzing Petri nets using Spin"
55.abstract:"The Spin model checker is a system that has been used to model and analyze a large number of applications in several domains including the aerospace industry. One of the novelties of Spin is its relatively simple specification language, Promela, as well as the powerful abilities of the model checker. The Petri net notation is a mathematical tool for modeling various classes of systems, especially those that involve concurrency and parallelism. The Honeywell Domain Modeling Environment (DOME) is a tool that supports system design using a wide variety of modeling notations, including UML diagrams and Petri nets. We describe a tool that supports the use of the Spin model checker to analyze and verify Petri net specifications that have been constructed using the DOME tool. In addition to discussing the translation of Petri nets into Promela, we present several example Petri net specifications as well as their analysis using Spin."
55.url:http://dx.doi.org/10.1109/ASE.2001.989839
55.opinion:exclude

56.title:"Formally testing fail-safety of electronic purse protocols"
56.abstract:"Designing and implementing security-critical systems correctly is difficult. In practice, most vulnerabilities arise from bugs in implementations. We present work towards systematic specification-based testing of security-critical systems using the CASE tool AutoFocus. Cryptographic systems are formally specified with state transition diagrams, a notation for state machines in the AutoFocus system., We show how to systematically generate test sequences for security properties based on the model that can be used to test the implementation for vulnerabilities. In particular we focus on the principle of fail-safety. We explain our method at the example of a part of the Common Electronic Purse Specifications (CEPS). Most commonly, attacks address vulnerabilities in the way security mechanisms are used, rather than the mechanisms themselves. Being able to treat security aspects with a general CASE tool within the context of system development enables detection of such vulnerabilities."
56.url:http://dx.doi.org/10.1109/ASE.2001.989840
56.opinion:exclude

57.title:"Automata-based verification of temporal properties on running programs"
57.abstract:"This paper presents an approach to checking a running program against Linear Temporal Logic (LTL) specifications. LTL is a widely used logic for expressing properties of programs viewed as sets of executions. Our approach consists of translating LTL formulae to finite-state automata, which are used as observers of the program behavior. The translation algorithm we propose modifies standard LTL to Buchi automata conversion techniques to generate automata that check finite program traces. The algorithm has been implemented in a tool, which has been integrated with the generic JPaX framework for runtime analysis of Java programs."
57.url:http://dx.doi.org/10.1109/ASE.2001.989841
57.opinion:exclude

58.title:"Towards an evolutionary formal software development"
58.abstract:"Although formal methods have been successfully applied in various industrial applications, their use in software development is still restricted to individual case studies. To overcome this situation we aim at a methodology for an evolutionary formal software development which allows for a stepwise and incremental development process along the line of rapid prototyping. The approach is based on work on a formal management of change for formal developments which is able to maintain proofs when changing specifications."
58.url:http://dx.doi.org/10.1109/ASE.2001.989842
58.opinion:exclude

59.title:"A concurrency test tool for Java monitors"
59.abstract:"The Java programming language supports monitors. Monitor implementations, like other concurrent programs, are hard to test due to the inherent non-determinism. This paper presents the ConAn (Concurrency Analyser) tool for generating drivers for the testing of Java monitors. To obtain adequate controllability over the interactions between Java threads, the generated driver contains processes that are synchronized by a clock. The driver automatically executes the calls in the test sequence in the prescribed order and compares the outputs against the expected outputs specified in the test sequence. The method and tool are illustrated on an asymmetric producer-consumer monitor and their application to two other monitors is discussed."
59.url:http://dx.doi.org/10.1109/ASE.2001.989843
59.opinion:exclude

60.title:"Enforcing business policies through automated reconfiguration"
60.abstract:"In this paper, we address dynamic reconfiguration from the point of view of the enforcement of the policies that organisations wish to see imposed through the way information systems support business. We address the process of evolution by proposing a primitive-coordination context-for modelling the circumstances in which reconfiguration can and should take place. The idea is for business policies to emerge as properties of process executions when controlled through the coordination contexts that will have been defined for supporting business activities."
60.url:http://dx.doi.org/10.1109/ASE.2001.989844
60.opinion:exclude

61.title:"Design rationale for software maintenance"
61.abstract:"For a number of years, members of the artificial intelligence (AI) in design community have studied design rationale (DR), the reasons behind decisions made while designing. A record of what decisions were made, and why, is especially valuable for software maintenance. One reason for this is that the software lifecycle is a long one. Large projects may take years to complete and spend even more time out in the field being used (and maintained). The combination of a long lifecycle and the typically high personnel turnover in the software industry increases the probability that the original designer is unlikely to be available for consultation when problems arise. J. Lee's survey (1997) presents an excellent overview of DR research. There has also been work specific to software design, such as Boehm's WinWin (1994)."
61.url:http://dx.doi.org/10.1109/ASE.2001.989846
61.opinion:exclude

62.title:"Security specification and verification"
62.abstract:"Formalizing security requirements has received a significant attention since the 70s. However a general method for specifying security requirements is still missing. Especially, little work has been presented on specifying and verifying that a given application is a secure resource consumer The purpose of this work is to set up a methodology for (1) specifying security requirements of service providers and (2) proving that some application securely uses some resources. The developed theory will be evaluated and applied in two different areas: secure mobile code development and secure COTS-based software development."
62.url:http://dx.doi.org/10.1109/ASE.2001.989847
62.opinion:exclude

63.title:"Implementation of specification conjunction and domain interaction in Rosetta"
63.abstract:"Summary form only given. System level design is nowadays a complex process due to heterogeneity of domains of components in a single system. The language standard, Rosetta, was proposed as a means to help in such designs. An important feature in Rosetta is known as domain interaction and involves the analysis of interaction between models from domain to domain. The resulting iteration models can then be used to ensure correctness of the system at the design level. The goal of my doctoral dissertation is therefore to implement the semantics of domain interactions in Rosetta and to apply it in the specification of real world examples."
63.url:http://dx.doi.org/10.1109/ASE.2001.989848
63.opinion:exclude

64.title:"Automatic translation from UML specifications to B"
64.abstract:"Summary form only given. The research to merge the relatively simple and graphical nature of UML with the firm semantics bases of B has been mentioned several time in the literature. The goal is to propose automatic derivation schemes from UML to B specifications. Then, the construction of UML specifications is rigorously controlled by analyzing derived a specifications thanks to powerful B support tools. Dealing with the modeling UML behavioral diagrams in B, which has not been treated so far, is the main objective of the current work. We emphasize on the translation from use case, interaction and statechart diagrams into B specifications. We formalize each class operation, use case, event as a B operation which is encapsulated in a B abstract machine where are modeled the class data involved by the class operation, use case or event in question. In order to get the derived B specification more structured, we consider the class operation calling-called dependency, the use case structuring and the relation between events and its triggered transition. To complete the derivation schemes, we have proposed three derivation procedures based on class operations, use case and events I In addition, we have envisaged the following verifications on UML specifications: (i) the consistency of the class invariant; (ii) the conformity of object and state-chart diagrams regarding the class diagrams; (iii) the conformity of class operations, use cases regarding the class invariant; (iv) the class operation calling-called dependency and (v) the use case structuring."
64.url:http://dx.doi.org/10.1109/ASE.2001.989849
64.opinion:exclude

65.title:"Automated conversion from a requirements document to an executable formal specification"
65.abstract:"Many formal specification languages have been developed to engineer complex systems. However natural language (NL) has remained the choice of domain experts to specify the system because formal specification languages are not easy to master. Therefore NL requirements documentation must be reinterpreted by software engineers into a formal specification language. When the system is very complicated, which is mostly the case when one chooses to use formal specification, this conversion is both non-trivial and error-prone, if not implausible. This challenge comes from many factors such as miscommunication between domain experts and engineers. However the major bottleneck of this conversion is from the inborn characteristic of ambiguity of NL and the different level of the formalism between the two domains of NL and the formal specification. This is why there have been very few attempts to automate the conversion from requirements documentation to a formal specification language. This research project is developed as an application of formal specification and linguistic techniques to automate the conversion from a requirements document written in NL to a formal specification language. Contextual Natural Language Processing (CNLP) is used to handle the ambiguity problem in NL and Two Level Grammar (TLG) is used to deal with the different formalism level between NL and formal specification languages to achieve automated conversion from NL requirements documentation into a formal specification (in our case the Vienna Development Method - VDM++). A knowledge base is built from the NL requirements documentation using CNLP by parsing the documentation and storing the syntactic, semantic, and contextual information."
65.url:http://dx.doi.org/10.1109/ASE.2001.989850
65.opinion:exclude

66.title:"Automated test-data generation from formal models of software"
66.abstract:"Verification and Validation (V&V) of software for critical embedded control systems often consumes upto 70% of the development resources. Testing is one of the most frequently used V&V technique for verifying such systems. Many regulatory agencies that certify control systems for use require that the software be tested to certain specified levels of coverage. Currently, developing test cases to meet these requirements takes a major portion of the resources. Automating this task would result in significant time and cost savings. The objective of this paper is to automate the generation of such test cases. We propose an approach where we rely on a formal model of the required software behavior for test-case generation, as well as, an oracle to determine if the implementation produced the correct output during testing."
66.url:http://dx.doi.org/10.1109/ASE.2001.989851
66.opinion:exclude

67.title:"Model-checking real-time concurrent systems"
67.abstract:"Summary form only given, as follows. A concurrent real-time system is a system of many components, that should deliver the result in a particular time interval. The design of such a system is generally complex, with high possibility of errors. Thus it is very important to be able to verify the correctness of the design itself, before going on to implementation stage. Model-checking is a powerful approach to design verification which provides techniques for automatic determination of whether a design (model) of the system satisfies desired properties expressed in formal logic. Main problems that model-checking algorithms have to address are: state space of any concurrent system grows exponentially with the number of components of the system - state explosion problem; Addition of time (for modeling real-time systems) means that there are infinitely many concrete states of the system. Both of these mean that model-checking takes a long time and a lot of space. There are a number of approaches to model-checking providing partial solutions to these problems. However a lot of improvement is still desired to make practical model-checking of real systems feasible. Moreover, the more expressive the design technique is, and the more expressive the specification language is, the more complex becomes the problem of model-checking. Current state of the art model-checkers have fairly simple modeling means and specification languages, thus restricting developer in their capabilities. In this project a relatively new approach to model checking is taken - the use of abstract game theory, with the model-checking algorithm being implemented as an abstract game. In this approach reasoning is made over sets of states satisfying some properties, not individual states, thus reducing the size of the state-space to be searched. Also in this project the more expressive models of concurrent real-time systems and the more expressive specification logics are to be brought together to allow checking of complex properties of complex systems. A tangible deliverable will be a model-checking tool that should have a number of advantages over current state of the art model-checkers."
67.url:http://dx.doi.org/10.1109/ASE.2001.989852
67.opinion:exclude

68.title:"Verify properties of mobile code"
68.abstract:"Summary form only given. Given a program and a specification, you may want to verify mechanically and efficiently that this program satisfies the specification. Software verification techniques typically involve theorem proving. If a formal specification is easily available, consumption of computational resources is a major issue. Meanwhile, we shall not overlook the psychological factors. Often, you need extra expertise to verify a program. Tools that can automatically verify programs are helpful. On the other hand, ubiquitous computing has made the correctness of a program both a security and a performance issue. If you run a piece of mobile code on your machine, you will expect that the code does not access storages unlawfully. To make sure bad things won't happen, performance is sacrificed. If programs are written in an intermediate language that is able to capture and verify properties mentioned above, your host machine will benefit from it. This paper focuses on providing a type-theoretic solution to the verification of mobile programs. One of our primary tools is index types. Index types are a form of non-traditional types. An index type system extends the type system of a language with indices and predicates on those indices. Index types can express properties of program. To type check a program annotated with index types, we often will call an external decision procedure. Another concept used is the proof-carrying code. One of the major advantages of proof-carrying code is that a lot of theorem proving is shifted offline. When we use proof-carrying code to verify a property, the time spent on verification is mainly on proof-checking, which is considerably cheaper than theorem proving."
68.url:http://dx.doi.org/10.1109/ASE.2001.989853
68.opinion:exclude

